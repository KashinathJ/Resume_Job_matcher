{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KashinathJ/Resume_Job_matcher/blob/main/Resume_job_matching.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import fitz  # PyMuPDF for PDF parsing\n",
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Specify the path to the Kaggle Resume Dataset and job descriptions from Hugging Face\n",
        "hugging_face_dataset = load_dataset(\"jacob-hugging-face/job-descriptions\")\n",
        "job_descriptions = hugging_face_dataset['train']['job_description'] #JD of jobs\n",
        "job_company =  hugging_face_dataset['train']['company_name'] #company names\n",
        "job_role = hugging_face_dataset['train']['position_title'] #position\n",
        "\n",
        "# Initialize DistilBERT tokenizer and model\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "# Job Description Data sclidin\n",
        "job_descriptions1 = job_descriptions[:15]  #  10-15 job descriptions\n",
        "\n",
        "# Candidate-Job Matching - cosine similarity\n",
        "def calculate_cosine_similarity(embeddings_1, embeddings_2):\n",
        "    return cosine_similarity(embeddings_1, embeddings_2)\n",
        "\n",
        "# Process job descriptions and store their embeddings\n",
        "job_desc_embeddings = []\n",
        "for job_desc in job_descriptions:\n",
        "    inputs = tokenizer(job_desc, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    outputs = model(**inputs)\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
        "    job_desc_embeddings.append(embeddings)\n",
        "\n",
        "\n",
        "# Read the resumes from the CSV file\n",
        "resume_df = pd.read_csv(\"/content/Resume.csv\")\n",
        "resume_texts = resume_df['Resume_str'] #complete details\n",
        "\n",
        "resume_category = resume_df['Category'] #category\n",
        "\n",
        "resume_texts1 = resume_texts#5 resumes\n",
        "\n",
        "print(resume_texts[1])\n",
        "print(type(resume_texts))\n",
        "words = resume_texts.split()\n",
        "for i in range(len(words)):\n",
        "    if words[i] == \"Education\":\n",
        "        extracted_name = words[i:] if i + 1 < len(words) else None\n",
        "        break\n",
        "\n",
        "sk_edu = ' '.join(extracted_name)\n",
        "print(sk_edu)\n",
        "\n",
        "#extracting education\n",
        "edu_words = sk_edu.split()\n",
        "for i in range(len(edu_words)):\n",
        "    if edu_words[i] == \"Skills\":\n",
        "        edu_extract = edu_words[:i] if i + 1 < len(edu_words) else None\n",
        "        break\n",
        "\n",
        "Education = ' '.join(edu_extract)\n",
        "print(Education)\n",
        "\n",
        "#extracting skills\n",
        "edu_words = sk_edu.split()\n",
        "for i in range(len(edu_words)):\n",
        "    if edu_words[i] == \"Skills\":\n",
        "        edu_extract = edu_words[i:] if i + 1 < len(edu_words) else None\n",
        "        break\n",
        "\n",
        "Skills = ' '.join(edu_extract)\n",
        "print(Skills)\n",
        "\n",
        "# Process resumes and match them with job descriptions\n",
        "resume_matches = {}\n",
        "for i, resume_text in enumerate(resume_texts):\n",
        "    inputs = tokenizer(resume_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    outputs = model(**inputs)\n",
        "    resume_embeddings = outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
        "\n",
        "    #  cosine similarity with job descriptions\n",
        "    similarity_scores = [cosine_similarity(job_emb.reshape(1, -1), resume_embeddings.reshape(1, -1))[0][0] for job_emb in job_desc_embeddings]\n",
        "\n",
        "    # Find the index of the top match\n",
        "    top_match_index = np.argmax(similarity_scores)\n",
        "\n",
        "    # Store the top match for each resume\n",
        "    resume_matches[resume_text] = (job_company[top_match_index], job_role[top_match_index], job_descriptions1[top_match_index], similarity_scores[top_match_index] )\n",
        "\n",
        "# Print the top match for each resume\n",
        "for resume_text,  (comp,  role, job_desc,score) in resume_matches.items():\n",
        "    print(f\"Resume: {resume_text[:100]}...\\nCompany:{comp}...\\nRole:{role} \\nJob Description: {job_desc[:100]}... \\nSimilarity Score: {score:.2f}\\n\")\n"
      ],
      "metadata": {
        "id": "lqPt-vUGEnKV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}